{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import warnings\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BankDepositPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_name = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.feature_columns = []\n",
    "\n",
    "    def preprocess_data(self, data, is_training=True):\n",
    "        data = data.copy()\n",
    "\n",
    "        # Handling missing values\n",
    "        data.fillna(data.mode().iloc[0], inplace=True)\n",
    "\n",
    "        # Encoding categorical features\n",
    "        categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_columns:\n",
    "            if is_training:\n",
    "                le = LabelEncoder()\n",
    "                data[col] = le.fit_transform(data[col])\n",
    "                self.label_encoders[col] = le\n",
    "            else:\n",
    "                le = self.label_encoders.get(col)\n",
    "                if le:\n",
    "                    data[col] = data[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "                    data[col] = le.transform(data[col])\n",
    "                else:\n",
    "                    raise NotFittedError(f\"LabelEncoder for {col} not found. Fit the model first.\")\n",
    "\n",
    "        # Feature engineering (add example interaction features)\n",
    "        if 'pemasukan' in data.columns and 'jumlah_tanggungan' in data.columns:\n",
    "            data['rasio_pemasukan_tanggungan'] = data['pemasukan'] / (data['jumlah_tanggungan'] + 1)\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        if 'customer_number' in data.columns:\n",
    "            data.drop(columns=['customer_number'], inplace=True)\n",
    "\n",
    "        if is_training and 'berlangganan_deposito' in data.columns:\n",
    "            self.feature_columns = [col for col in data.columns if col != 'berlangganan_deposito']\n",
    "\n",
    "        return data\n",
    "\n",
    "    def train_model(self, df):\n",
    "        df = self.preprocess_data(df, is_training=True)\n",
    "        X = df[self.feature_columns]\n",
    "        y = df['berlangganan_deposito']\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "\n",
    "        model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"GradientBoosting AUC: {auc:.4f}\")\n",
    "\n",
    "        self.model = model\n",
    "        self.model_name = \"GradientBoosting\"\n",
    "\n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"auc_score\": auc\n",
    "        }\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        new_data = self.preprocess_data(new_data, is_training=False)\n",
    "        X_new = new_data[self.feature_columns]\n",
    "        X_new_scaled = self.scaler.transform(X_new)\n",
    "        return self.model.predict_proba(X_new_scaled)[:, 1]\n",
    "\n",
    "    def save_model(self, path):\n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'scaler': self.scaler,\n",
    "            'encoders': self.label_encoders,\n",
    "            'features': self.feature_columns,\n",
    "            'model_name': self.model_name\n",
    "        }, path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        model_dict = joblib.load(path)\n",
    "        self.model = model_dict['model']\n",
    "        self.scaler = model_dict['scaler']\n",
    "        self.label_encoders = model_dict['encoders']\n",
    "        self.feature_columns = model_dict['features']\n",
    "        self.model_name = model_dict['model_name']\n",
    "\n",
    "    def save_predictions(self, customer_number, y_test_pred, filename='submission.csv'):\n",
    "        submission = pd.DataFrame({\n",
    "            'customer_number': customer_number,\n",
    "            'berlangganan_deposito': y_test_pred\n",
    "        })\n",
    "        submission.to_csv(filename, index=False)\n",
    "        return filename\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè¶ Bank Deposit Prediction System\n",
      "==================================================\n",
      "\n",
      "üìÅ Loading training data...\n",
      "‚úÖ Training data loaded: (22916, 22)\n",
      "\n",
      "üìä Column info:\n",
      "Total columns: 22\n",
      "Columns: ['customer_number', 'usia', 'pekerjaan', 'status_perkawinan', 'pendidikan', 'gagal_bayar_sebelumnya', 'pinjaman_rumah', 'pinjaman_pribadi', 'jenis_kontak', 'bulan_kontak_terakhir', 'hari_kontak_terakhir', 'jumlah_kontak_kampanye_ini', 'hari_sejak_kontak_sebelumnya', 'jumlah_kontak_sebelumnya', 'hasil_kampanye_sebelumnya', 'tingkat_variasi_pekerjaan', 'indeks_harga_konsumen', 'indeks_kepercayaan_konsumen', 'suku_bunga_euribor_3bln', 'jumlah_pekerja', 'pulau', 'berlangganan_deposito']\n",
      "\n",
      "üîç Data types:\n",
      "   customer_number: int64 | Unique: 22916 | Nulls: 0\n",
      "   usia: int64 | Unique: 78 | Nulls: 0\n",
      "   pekerjaan: object | Unique: 12 | Nulls: 0\n",
      "   status_perkawinan: object | Unique: 4 | Nulls: 0\n",
      "   pendidikan: object | Unique: 8 | Nulls: 0\n",
      "   gagal_bayar_sebelumnya: object | Unique: 3 | Nulls: 0\n",
      "   pinjaman_rumah: object | Unique: 3 | Nulls: 0\n",
      "   pinjaman_pribadi: object | Unique: 3 | Nulls: 0\n",
      "   jenis_kontak: object | Unique: 2 | Nulls: 0\n",
      "   bulan_kontak_terakhir: object | Unique: 10 | Nulls: 0\n",
      "   hari_kontak_terakhir: object | Unique: 5 | Nulls: 0\n",
      "   jumlah_kontak_kampanye_ini: int64 | Unique: 40 | Nulls: 0\n",
      "   hari_sejak_kontak_sebelumnya: int64 | Unique: 25 | Nulls: 0\n",
      "   jumlah_kontak_sebelumnya: int64 | Unique: 8 | Nulls: 0\n",
      "   hasil_kampanye_sebelumnya: object | Unique: 3 | Nulls: 0\n",
      "   tingkat_variasi_pekerjaan: float64 | Unique: 10 | Nulls: 0\n",
      "   indeks_harga_konsumen: float64 | Unique: 26 | Nulls: 0\n",
      "   indeks_kepercayaan_konsumen: float64 | Unique: 26 | Nulls: 0\n",
      "   suku_bunga_euribor_3bln: float64 | Unique: 306 | Nulls: 0\n",
      "   jumlah_pekerja: float64 | Unique: 11 | Nulls: 0\n",
      "   pulau: object | Unique: 8 | Nulls: 0\n",
      "   berlangganan_deposito: int64 | Unique: 2 | Nulls: 0\n",
      "\n",
      "üìà Target distribution:\n",
      "berlangganan_deposito\n",
      "0    20302\n",
      "1     2614\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìÅ Loading validation data...\n",
      "‚úÖ Validation data loaded: (5729, 21)\n"
     ]
    }
   ],
   "source": [
    "print(\"üè¶ Bank Deposit Prediction System\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load training dataset\n",
    "print(\"\\nüìÅ Loading training data...\")\n",
    "try:\n",
    "    train_data = pd.read_csv('https://raw.githubusercontent.com/difadlyaulhaq/Data_Quest_Hackathon/c73ff0ec05c5706f574a10b00556057dce362346/training_dataset.csv')\n",
    "    print(f\"‚úÖ Training data loaded: {train_data.shape}\")\n",
    "    \n",
    "    # Explore data structure\n",
    "    print(f\"\\nüìä Column info:\")\n",
    "    print(f\"Total columns: {len(train_data.columns)}\")\n",
    "    print(f\"Columns: {train_data.columns.tolist()}\")\n",
    "    \n",
    "    print(f\"\\nüîç Data types:\")\n",
    "    for col in train_data.columns:\n",
    "        dtype = train_data[col].dtype\n",
    "        nunique = train_data[col].nunique()\n",
    "        null_count = train_data[col].isnull().sum()\n",
    "        print(f\"   {col}: {dtype} | Unique: {nunique} | Nulls: {null_count}\")\n",
    "    \n",
    "    if 'berlangganan_deposito' in train_data.columns:\n",
    "        print(f\"\\nüìà Target distribution:\")\n",
    "        print(train_data['berlangganan_deposito'].value_counts())\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Target column 'berlangganan_deposito' not found!\")\n",
    "        print(f\"Available columns: {train_data.columns.tolist()}\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå File 'training_dataset.csv' tidak ditemukan!\")\n",
    "    print(\"   Pastikan file ada di directory yang sama dengan notebook ini\")\n",
    "\n",
    "# Load validation dataset\n",
    "print(\"\\nüìÅ Loading validation data...\")\n",
    "try:\n",
    "    validation_data = pd.read_csv('https://raw.githubusercontent.com/difadlyaulhaq/Data_Quest_Hackathon/c73ff0ec05c5706f574a10b00556057dce362346/validation_set.csv')\n",
    "    print(f\"‚úÖ Validation data loaded: {validation_data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå File 'validation_dataset.csv' tidak ditemukan!\")\n",
    "    print(\"   Pastikan file ada di directory yang sama dengan notebook ini.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Training model...\n",
      "GradientBoosting AUC: 0.7998\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi predictor\n",
    "predictor = BankDepositPredictor()\n",
    "\n",
    "# Train model\n",
    "print(\"\\nüîß Training model...\")\n",
    "model = predictor.train_model(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÆ Making predictions...\n",
      "\n",
      "üìä Sample predictions:\n",
      "[0.05395663 0.03551548 0.03482137 0.03720204 0.06693379 0.03509629\n",
      " 0.04331913 0.03545669 0.30902294 0.0710289 ]\n",
      "\n",
      "üìã Prediction Summary:\n",
      "   Total predictions: 5729\n",
      "   Model used: GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "print(\"\\nüîÆ Making predictions...\")\n",
    "predictions = predictor.predict(validation_data)\n",
    "\n",
    "# Display sample predictions\n",
    "print(f\"\\nüìä Sample predictions:\")\n",
    "print(predictions[:10])\n",
    "\n",
    "print(f\"\\nüìã Prediction Summary:\")\n",
    "print(f\"   Total predictions: {len(predictions)}\")\n",
    "print(f\"   Model used: {predictor.model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Saving predictions...\n",
      "\n",
      "üéâ Process completed successfully!\n",
      "üìÅ File saved: submission.csv\n",
      "üìä Ready for submission!\n",
      "\n",
      "üîç Verifying file format...\n",
      "0       0.053957\n",
      "1       0.035515\n",
      "2       0.034821\n",
      "3       0.037202\n",
      "4       0.066934\n",
      "          ...   \n",
      "5724    0.043218\n",
      "5725    0.042101\n",
      "5726    0.034469\n",
      "5727    0.066810\n",
      "5728    0.041142\n",
      "Name: berlangganan_deposito, Length: 5729, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüíæ Saving predictions...\")\n",
    "filename = predictor.save_predictions(validation_data['customer_number'], predictions, 'submission.csv')\n",
    "\n",
    "\n",
    "print(f\"\\nüéâ Process completed successfully!\")\n",
    "print(f\"üìÅ File saved: {filename}\")\n",
    "print(f\"üìä Ready for submission!\")\n",
    "\n",
    "# Verify file format\n",
    "print(f\"\\nüîç Verifying file format...\")\n",
    "saved_data = pd.read_csv('submission.csv')  # Tambahkan ini!\n",
    "print(saved_data['berlangganan_deposito'])  # Tambahkan ini!\n",
    "# saved_data['berlangganan_deposito'] = saved_data['berlangganan_deposito'].astype(int)\n",
    "# print(f\"   Columns: {saved_data.columns.tolist()}\")\n",
    "# print(f\"   Shape: {saved_data.shape}\")\n",
    "# print(f\"   Probability range: [{saved_data['berlangganan_deposito'].min():.4f}, {saved_data['berlangganan_deposito'].max():.4f}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
