{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a96cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦ Single Improved Bank Deposit Prediction System\n",
      "==================================================\n",
      "\n",
      "ğŸ“ Loading training data...\n",
      "âœ… Training data loaded: (22916, 22)\n",
      "\n",
      "ğŸ“ Loading validation data...\n",
      "âœ… Validation data loaded: (5729, 21)\n",
      "\n",
      "ğŸ”§ Training model with proper cross-validation...\n",
      "Cross-Validation Results:\n",
      "CV AUC: 0.7943 (+/- 0.0095)\n",
      "Individual CV scores: ['0.7798', '0.7980', '0.8089', '0.7912', '0.7936']\n",
      "\n",
      "ğŸ¯ Model: GradientBoosting\n",
      "ğŸ¯ CV AUC Score: 0.7943 (+/- 0.0095)\n",
      "ğŸ“Š Expected performance on unseen data: ~0.7943\n",
      "\n",
      "ğŸ”® Making predictions...\n",
      "\n",
      "ğŸ’¾ Saving predictions...\n",
      "\n",
      "ğŸ‰ Process completed successfully!\n",
      "ğŸ“ File saved: improved_submission.csv\n",
      "ğŸ“Š Prediction range: [0.0172, 0.8685]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import joblib\n",
    "\n",
    "class SingleImprovedBankDepositPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.model_name = \"GradientBoosting\"\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.feature_columns = []\n",
    "\n",
    "    def preprocess_data(self, data, is_training=True):\n",
    "        data = data.copy()\n",
    "\n",
    "        # Handle missing values\n",
    "        data.fillna(data.mode().iloc[0], inplace=True)\n",
    "\n",
    "        # Encoding categorical features\n",
    "        categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "        for col in categorical_columns:\n",
    "            if is_training:\n",
    "                le = LabelEncoder()\n",
    "                data[col] = le.fit_transform(data[col])\n",
    "                self.label_encoders[col] = le\n",
    "            else:\n",
    "                le = self.label_encoders.get(col)\n",
    "                if le:\n",
    "                    # Handle unseen categories\n",
    "                    data[col] = data[col].apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
    "                    data[col] = le.transform(data[col])\n",
    "                else:\n",
    "                    raise NotFittedError(f\"LabelEncoder for {col} not found.\")\n",
    "\n",
    "        # Simple feature engineering - only use existing columns\n",
    "        if 'jumlah_kontak_kampanye_ini' in data.columns and 'jumlah_kontak_sebelumnya' in data.columns:\n",
    "            data['total_kontak'] = data['jumlah_kontak_kampanye_ini'] + data['jumlah_kontak_sebelumnya']\n",
    "\n",
    "        # Drop unnecessary columns\n",
    "        if 'customer_number' in data.columns:\n",
    "            data.drop(columns=['customer_number'], inplace=True)\n",
    "\n",
    "        if is_training and 'berlangganan_deposito' in data.columns:\n",
    "            self.feature_columns = [col for col in data.columns if col != 'berlangganan_deposito']\n",
    "\n",
    "        return data\n",
    "\n",
    "    def train_model_with_proper_cv(self, df):\n",
    "        \"\"\"Train model with proper cross-validation to get realistic performance estimate\"\"\"\n",
    "        df = self.preprocess_data(df, is_training=True)\n",
    "        X = df[self.feature_columns]\n",
    "        y = df['berlangganan_deposito']\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # Use StratifiedKFold for proper cross-validation\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Model with slight regularization to prevent overfitting\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=100, \n",
    "            learning_rate=0.1,\n",
    "            max_depth=3,  # Reduce depth to prevent overfitting\n",
    "            min_samples_split=20,  # Require more samples to split\n",
    "            min_samples_leaf=10,   # Require more samples in leaf\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Get cross-validation scores\n",
    "        cv_scores = cross_val_score(model, X_scaled, y, cv=skf, scoring='roc_auc')\n",
    "        mean_cv_score = cv_scores.mean()\n",
    "        std_cv_score = cv_scores.std()\n",
    "        \n",
    "        print(f\"Cross-Validation Results:\")\n",
    "        print(f\"CV AUC: {mean_cv_score:.4f} (+/- {std_cv_score:.4f})\")\n",
    "        print(f\"Individual CV scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
    "        \n",
    "        # Train final model on full dataset\n",
    "        model.fit(X_scaled, y)\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        return {\n",
    "            \"model_name\": self.model_name,\n",
    "            \"cv_auc_score\": mean_cv_score,\n",
    "            \"cv_std\": std_cv_score\n",
    "        }\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        if self.model is None:\n",
    "            raise NotFittedError(\"Model not trained yet.\")\n",
    "            \n",
    "        new_data = self.preprocess_data(new_data, is_training=False)\n",
    "        X_new = new_data[self.feature_columns]\n",
    "        X_new_scaled = self.scaler.transform(X_new)\n",
    "        return self.model.predict_proba(X_new_scaled)[:, 1]\n",
    "\n",
    "    def save_model(self, path):\n",
    "        joblib.dump({\n",
    "            'model': self.model,\n",
    "            'scaler': self.scaler,\n",
    "            'encoders': self.label_encoders,\n",
    "            'features': self.feature_columns,\n",
    "            'model_name': self.model_name\n",
    "        }, path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        model_dict = joblib.load(path)\n",
    "        self.model = model_dict['model']\n",
    "        self.scaler = model_dict['scaler']\n",
    "        self.label_encoders = model_dict['encoders']\n",
    "        self.feature_columns = model_dict['features']\n",
    "        self.model_name = model_dict['model_name']\n",
    "\n",
    "    def save_predictions(self, customer_number, y_test_pred, filename='submission.csv'):\n",
    "        submission = pd.DataFrame({\n",
    "            'customer_number': customer_number,\n",
    "            'berlangganan_deposito': y_test_pred\n",
    "        })\n",
    "        submission.to_csv(filename, index=False)\n",
    "        return filename\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    print(\"ğŸ¦ Single Improved Bank Deposit Prediction System\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\nğŸ“ Loading training data...\")\n",
    "    train_data = pd.read_csv('https://raw.githubusercontent.com/difadlyaulhaq/junk/refs/heads/main/training_dataset.csv')\n",
    "    print(f\"âœ… Training data loaded: {train_data.shape}\")\n",
    "    \n",
    "    print(\"\\nğŸ“ Loading validation data...\")\n",
    "    validation_data = pd.read_csv('https://raw.githubusercontent.com/difadlyaulhaq/junk/refs/heads/main/validation_set.csv')\n",
    "    print(f\"âœ… Validation data loaded: {validation_data.shape}\")\n",
    "    \n",
    "    # Initialize and train predictor\n",
    "    predictor = SingleImprovedBankDepositPredictor()\n",
    "    \n",
    "    print(\"\\nğŸ”§ Training model with proper cross-validation...\")\n",
    "    result = predictor.train_model_with_proper_cv(train_data)\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Model: {result['model_name']}\")\n",
    "    print(f\"ğŸ¯ CV AUC Score: {result['cv_auc_score']:.4f} (+/- {result['cv_std']:.4f})\")\n",
    "    print(f\"ğŸ“Š Expected performance on unseen data: ~{result['cv_auc_score']:.4f}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"\\nğŸ”® Making predictions...\")\n",
    "    predictions = predictor.predict(validation_data)\n",
    "    \n",
    "    # Save predictions\n",
    "    print(\"\\nğŸ’¾ Saving predictions...\")\n",
    "    filename = predictor.save_predictions(validation_data['customer_number'], predictions, 'improved_submission.csv')\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Process completed successfully!\")\n",
    "    print(f\"ğŸ“ File saved: {filename}\")\n",
    "    print(f\"ğŸ“Š Prediction range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
